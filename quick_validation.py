#!/usr/bin/env python3
"""
Quick Validation Script for AI Data Analytics Tool
Tests core functionality across all domains quickly
"""

import os
import sys
import time
from datetime import datetime

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import our backend
try:
    from backend import AnalyticsWorkflow
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… Backend imported successfully")
except ImportError as e:
    print(f"âŒ Failed to import backend: {e}")
    sys.exit(1)

def test_quick_validation():
    """Quick validation test across all domains"""
    print("\nğŸš€ QUICK VALIDATION TEST")
    print("=" * 50)
    
    workflow = AnalyticsWorkflow()
    
    # Quick tests for each domain
    quick_tests = [
        ("banking", "What is the customer churn rate?"),
        ("hospital", "What is our readmission rate?"),
        ("marketing", "What's the conversion rate?"),
    ]
    
    results = []
    
    for domain, question in quick_tests:
        print(f"\nğŸ§ª Testing {domain.upper()}: {question}")
        try:
            start_time = time.time()
            result = workflow.process_query(domain, question)
            duration = time.time() - start_time
            
            if result and result.get('analysis'):
                print(f"   âœ… Success! ({duration:.1f}s)")
                print(f"   ğŸ“Š Analysis length: {len(result['analysis'])} characters")
                
                # Check if chart was generated
                if os.path.exists('output'):
                    charts = [f for f in os.listdir('output') if f.endswith('.png')]
                    if charts:
                        print(f"   ğŸ“ˆ Chart generated: {charts[0]}")
                
                results.append((domain, True, duration))
            else:
                print(f"   âŒ Failed - No analysis returned")
                results.append((domain, False, duration))
                
        except Exception as e:
            print(f"   âŒ Error: {e}")
            results.append((domain, False, 0))
    
    # Summary
    print(f"\n" + "=" * 50)
    print("ğŸ“‹ QUICK VALIDATION SUMMARY")
    print("=" * 50)
    
    successful = sum(1 for _, success, _ in results if success)
    total = len(results)
    
    print(f"âœ… Successful tests: {successful}/{total}")
    print(f"ğŸ“Š Success rate: {successful/total*100:.1f}%")
    
    if successful == total:
        print("ğŸ‰ ALL QUICK TESTS PASSED - Tool is working correctly!")
    else:
        print("âš ï¸ Some tests failed - Check detailed output above")
    
    return successful == total

def test_conversation_memory():
    """Test conversation memory with follow-up questions"""
    print("\nğŸ§  CONVERSATION MEMORY TEST")
    print("=" * 50)
    
    workflow = AnalyticsWorkflow()
    
    # Progressive conversation
    questions = [
        "Show me the customer churn rate by account type",
        "Focus on the high-churn group and show their demographics",
        "What strategies would you recommend for those customers?"
    ]
    
    conversation_history = []
    
    for i, question in enumerate(questions, 1):
        print(f"\nğŸ’¬ Question {i}: {question}")
        try:
            start_time = time.time()
            result = workflow.process_query('banking', question, conversation_history)
            duration = time.time() - start_time
            
            if result and result.get('analysis'):
                print(f"   âœ… Success! ({duration:.1f}s)")
                
                # Add to conversation history
                conversation_history.append({
                    'role': 'user',
                    'content': question,
                    'domain': 'banking'
                })
                conversation_history.append({
                    'role': 'assistant',
                    'content': result['analysis'],
                    'domain': 'banking'
                })
                
                # Show brief excerpt
                excerpt = result['analysis'][:200] + "..." if len(result['analysis']) > 200 else result['analysis']
                print(f"   ğŸ“ Response excerpt: {excerpt}")
            else:
                print(f"   âŒ Failed - No analysis returned")
                return False
                
        except Exception as e:
            print(f"   âŒ Error: {e}")
            return False
    
    print("\nâœ… CONVERSATION MEMORY TEST PASSED!")
    print("ğŸ”— Tool successfully maintained context across questions")
    return True

def test_chart_generation():
    """Test chart generation and sizing"""
    print("\nğŸ“Š CHART GENERATION TEST")
    print("=" * 50)
    
    workflow = AnalyticsWorkflow()
    
    # Clear any existing charts
    workflow.clear_output_charts()
    
    # Test chart generation
    print("ğŸ§ª Testing chart generation with age data...")
    try:
        start_time = time.time()
        result = workflow.process_query('banking', 'Show customer age distribution')
        duration = time.time() - start_time
        
        if result and result.get('analysis'):
            print(f"   âœ… Analysis generated! ({duration:.1f}s)")
            
            # Check for chart
            if os.path.exists('output'):
                charts = [f for f in os.listdir('output') if f.endswith('.png')]
                if charts:
                    chart_path = os.path.join('output', charts[0])
                    file_size = os.path.getsize(chart_path)
                    print(f"   ğŸ“ˆ Chart generated: {charts[0]}")
                    print(f"   ğŸ“ File size: {file_size:,} bytes")
                    print(f"   ğŸ¯ Expected: 9Ã—5 inch chart at 100 DPI")
                    
                    # Test chart clearing
                    print("\nğŸ§¹ Testing chart clearing...")
                    workflow.clear_output_charts()
                    remaining_charts = [f for f in os.listdir('output') if f.endswith('.png')]
                    if len(remaining_charts) == 0:
                        print("   âœ… Chart clearing works!")
                    else:
                        print(f"   âš ï¸ {len(remaining_charts)} charts remain after clearing")
                    
                    return True
                else:
                    print("   âŒ No chart file generated")
                    return False
            else:
                print("   âŒ Output directory not found")
                return False
        else:
            print("   âŒ Failed - No analysis returned")
            return False
            
    except Exception as e:
        print(f"   âŒ Error: {e}")
        return False

def test_domain_switching():
    """Test switching between domains"""
    print("\nğŸ”„ DOMAIN SWITCHING TEST")
    print("=" * 50)
    
    workflow = AnalyticsWorkflow()
    
    domains = ['banking', 'hospital', 'marketing']
    questions = [
        "What is the churn rate?",
        "What is the readmission rate?", 
        "What is the conversion rate?"
    ]
    
    for domain, question in zip(domains, questions):
        print(f"\nğŸ¢ Switching to {domain.upper()}: {question}")
        try:
            start_time = time.time()
            result = workflow.process_query(domain, question)
            duration = time.time() - start_time
            
            if result and result.get('analysis'):
                print(f"   âœ… Success! ({duration:.1f}s)")
                # Show domain-specific context
                analysis_preview = result['analysis'][:150] + "..."
                print(f"   ğŸ“Š Analysis: {analysis_preview}")
            else:
                print(f"   âŒ Failed - No analysis returned")
                return False
                
        except Exception as e:
            print(f"   âŒ Error: {e}")
            return False
    
    print("\nâœ… DOMAIN SWITCHING TEST PASSED!")
    print("ğŸ”„ Tool successfully handled all three domains")
    return True

def main():
    """Run quick validation tests"""
    print("ğŸ§ª AI DATA ANALYTICS TOOL - QUICK VALIDATION")
    print("=" * 60)
    print("Running essential tests to validate core functionality")
    print("Estimated runtime: 2-3 minutes")
    print("=" * 60)
    
    all_tests_passed = True
    
    # Run core validation tests
    tests = [
        ("Core Functionality", test_quick_validation),
        ("Conversation Memory", test_conversation_memory),
        ("Chart Generation", test_chart_generation),
        ("Domain Switching", test_domain_switching),
    ]
    
    for test_name, test_func in tests:
        try:
            print(f"\nğŸš€ Running {test_name} Test...")
            result = test_func()
            if not result:
                all_tests_passed = False
                print(f"âŒ {test_name} test failed!")
            else:
                print(f"âœ… {test_name} test passed!")
        except Exception as e:
            print(f"âŒ {test_name} test crashed: {e}")
            all_tests_passed = False
    
    # Final summary
    print("\n" + "=" * 60)
    print("ğŸ¯ QUICK VALIDATION SUMMARY")
    print("=" * 60)
    
    if all_tests_passed:
        print("ğŸ‰ ALL VALIDATION TESTS PASSED!")
        print("âœ… Tool is ready for demonstration and production use")
        print("ğŸš€ Core functionality verified across all domains")
        print("ğŸ’¡ Conversation memory and chart generation working")
    else:
        print("âš ï¸ SOME VALIDATION TESTS FAILED")
        print("âŒ Review the failed tests above")
        print("ğŸ”§ Fix issues before proceeding to full demo")
    
    print("\nğŸ’¡ For comprehensive testing, run: python run_comprehensive_tests.py")

if __name__ == "__main__":
    main()
